{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de2244c0-ddab-478e-8b8f-69125abfedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##[3주차] 심화과제: Pre-trained모델로 효율적인 NLP 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87498508-ef50-4e00-9e8a-e8a94621bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. 데이터 로드 및 전처리\n",
    "## 먼저 Kaggle에서 제공하는 NER 데이터셋을 다운로드하고, 이를 토대로 NER 문제를 푸는 구조로 변경합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c50a23b1-dad0-4927-b939-52d9562e21dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.6)\n",
      "Path to dataset files: /Users/nabakgood/.cache/kagglehub/datasets/debasisdotcom/name-entity-recognition-ner-dataset/versions/1\n",
      "    Sentence #           Word  POS Tag\n",
      "0  Sentence: 1      Thousands  NNS   O\n",
      "1          NaN             of   IN   O\n",
      "2          NaN  demonstrators  NNS   O\n",
      "3          NaN           have  VBP   O\n",
      "4          NaN        marched  VBN   O\n",
      "Index(['Sentence #', 'Word', 'POS', 'Tag'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertForTokenClassification, AdamW, BertForTokenClassification, BertConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# 데이터셋 다운로드\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"debasisdotcom/name-entity-recognition-ner-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# 데이터 로드 (파일 경로에 맞게 변경)\n",
    "train_df = pd.read_csv(f'{path}/NER dataset.csv', encoding='ISO-8859-1')  # ISO-8859-1 인코딩 사용\n",
    "print(train_df.head())\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48d38340-7732-4c87-8d4f-5235c60eabd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##2. 토큰화 및 데이터셋 생성\n",
    "##DistilBERT를 사용하려면, 먼저 DistilBERT의 토크나이저를 사용해 데이터를 적절하게 토큰화하고, 각 단어에 대해 레이블을 맞춰야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27b8d999-573e-478e-ab68-878d8d3082de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER 데이터셋을 위한 커스텀 Dataset 정의\n",
    "# NERDataset 클래스에 레이블 매핑 추가\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len=400):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.max_len = max_len\n",
    "        self.input_ids = []\n",
    "        self.attention_masks = []\n",
    "        self.labels = []\n",
    "\n",
    "        # 레이블 매핑 (태그를 숫자 인덱스로 변환)\n",
    "        self.label_map = {\n",
    "            'O': 0,         # No entity\n",
    "            'B-PER': 1,     # Beginning of a person\n",
    "            'I-PER': 2,     # Inside of a person\n",
    "            'B-ORG': 3,     # Beginning of an organization\n",
    "            'I-ORG': 4,     # Inside of an organization\n",
    "            'B-LOC': 5,     # Beginning of a location\n",
    "            'I-LOC': 6,     # Inside of a location\n",
    "            'B-MISC': 7,    # Beginning of a miscellaneous entity\n",
    "            'I-MISC': 8     # Inside of a miscellaneous entity\n",
    "        }\n",
    "\n",
    "        # Sentence # 기준으로 문장 묶기\n",
    "        sentences = defaultdict(list)\n",
    "        tags = defaultdict(list)\n",
    "\n",
    "        # 결측값 처리 및 데이터 정리\n",
    "        self.data['Word'] = self.data['Word'].fillna('')  # 결측값을 빈 문자열로 채움\n",
    "        self.data['Word'] = self.data['Word'].astype(str)  # 'Word' 컬럼을 문자열로 변환\n",
    "\n",
    "        # 각 문장을 Sentence # 기준으로 묶음\n",
    "        for _, row in self.data.iterrows():\n",
    "            sentence_id = row['Sentence #']\n",
    "            word = row['Word']\n",
    "            tag = row['Tag']\n",
    "\n",
    "            sentences[sentence_id].append(word)\n",
    "            tags[sentence_id].append(tag)\n",
    "\n",
    "        # 문장별로 처리\n",
    "        for sentence_id in sentences:\n",
    "            # 문장을 공백 기준으로 합침, 공백이 포함된 경우 제거\n",
    "            sentence = ' '.join([w for w in sentences[sentence_id] if w.strip()])  # 공백 제거\n",
    "            if not sentence:  # 빈 문장은 건너뜁니다.\n",
    "                continue\n",
    "            entity_tags = tags[sentence_id]  # 해당 문장의 엔티티 태그\n",
    "\n",
    "            # Tokenizer로 문장 전처리\n",
    "            encoding = self.tokenizer(sentence.split(), truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt')\n",
    "            \n",
    "            # 빈 문장이 아닌 경우에만 진행\n",
    "            if 'input_ids' not in encoding:\n",
    "                continue\n",
    "\n",
    "            input_ids = encoding['input_ids'][0].tolist()\n",
    "            attention_mask = encoding['attention_mask'][0].tolist()\n",
    "\n",
    "            # 레이블 생성 (단어별로 태그를 숫자로 할당)\n",
    "            label = [self.label_map.get(tag, 0) for tag in entity_tags]  # 매핑된 값 (기본값 0)\n",
    "\n",
    "            # 레이블이 최대 길이에 맞지 않으면 패딩\n",
    "            label += [0] * (self.max_len - len(label))\n",
    "\n",
    "            self.input_ids.append(input_ids)\n",
    "            self.attention_masks.append(attention_mask)\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx]),\n",
    "            'attention_mask': torch.tensor(self.attention_masks[idx]),\n",
    "            'labels': torch.tensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "# tokenizer 정의 (DistilBERT 사용)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# NERDataset 인스턴스화\n",
    "dataset = NERDataset(train_df, tokenizer)\n",
    "\n",
    "# 데이터셋을 리스트로 변환\n",
    "input_ids = dataset.input_ids\n",
    "attention_masks = dataset.attention_masks\n",
    "labels = dataset.labels\n",
    "\n",
    "# 데이터셋 분할 (훈련/테스트)\n",
    "train_inputs, test_inputs, train_labels, test_labels, train_masks, test_masks = train_test_split(\n",
    "    input_ids, labels, attention_masks, test_size=0.2\n",
    ")\n",
    "\n",
    "# 길이를 맞추기 위한 패딩/자르기\n",
    "max_len = 400\n",
    "\n",
    "def pad_sequence(sequence, max_len):\n",
    "    # 길이를 맞추기 위해 패딩하거나 자름\n",
    "    if len(sequence) > max_len:\n",
    "        return sequence[:max_len]\n",
    "    else:\n",
    "        return sequence + [0] * (max_len - len(sequence))\n",
    "\n",
    "# train_labels와 test_labels의 길이가 max_len을 초과하거나 부족할 경우 패딩을 추가\n",
    "train_labels = [pad_sequence(label, max_len) for label in train_labels]\n",
    "test_labels = [pad_sequence(label, max_len) for label in test_labels]\n",
    "\n",
    "# 새로운 데이터셋을 위한 DataLoader를 준비\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(train_inputs),\n",
    "    torch.tensor(train_masks),\n",
    "    torch.tensor(train_labels)\n",
    ")\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(test_inputs),\n",
    "    torch.tensor(test_masks),\n",
    "    torch.tensor(test_labels)\n",
    ")\n",
    "\n",
    "# 데이터로더\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "035550a5-efdf-4074-8147-8d7515a17a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. 모델 정의\n",
    "## DistilBERT 모델을 NER 문제에 맞게 fine-tuning합니다. (Pre-trained 모델)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a072ac91-bda6-4335-85cd-c153b906219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = DistilBertForTokenClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=len(dataset.label_map),  # 레이블 개수\n",
    ")\n",
    "\n",
    "device = torch.device('mps')\n",
    "pretrained_model = pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8efaccc6-c82e-4770-838e-ac344e436155",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Non-pre-trained 모델 설정 (새로 학습할 모델)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f3531b63-f727-45ee-b2e7-9337685112e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertConfig\n",
    "\n",
    "# DistilBERT 설정 (사전 훈련되지 않은 모델로 초기화)\n",
    "config = DistilBertConfig.from_pretrained('distilbert-base-uncased')\n",
    "config.num_labels = len(dataset.label_map)  # 레이블 수 설정\n",
    "\n",
    "# 사전 훈련되지 않은 DistilBERT 모델을 초기화\n",
    "non_pretrained_model = DistilBertForTokenClassification(config)\n",
    "non_pretrained_model = non_pretrained_model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "037097ec-7701-4ceb-9323-ffffcde27657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 옵티마이저 준비\n",
    "optimizer_pretrained = AdamW(pretrained_model.parameters(), lr=5e-5)\n",
    "optimizer_non_pretrained = AdamW(non_pretrained_model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "634624d2-321c-459d-aea0-717c5e2ed32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 함수\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 모델 예측\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # 손실 값 계산\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # 예측 결과\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        # 정확도 계산 (배치 크기 별로)\n",
    "        correct_predictions += (predictions == labels).sum().item()\n",
    "        total_predictions += labels.numel()\n",
    "        \n",
    "        # 역전파 및 파라미터 업데이트\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# 평가 함수\n",
    "def eval_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # 모델 예측\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # 예측 결과\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # 결과 반환\n",
    "    return classification_report(np.array(all_labels).flatten(), np.array(all_predictions).flatten(), output_dict=True), all_labels, all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1a9348c4-bdf6-443d-97bd-2da72c1010b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 모델 훈련 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3c024f7b-ca54-4954-9e74-cd3093123fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, test_loader, optimizer, device, num_epochs=3, model_type=\"Pretrained\"):\n",
    "    train_losses, test_losses = [], []\n",
    "    train_accuracies, test_accuracies = [], []  # 리스트 두 개로 초기화\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 모델을 훈련 모드로 설정\n",
    "        train_loss, train_correct, train_total = 0, 0, 0\n",
    "\n",
    "        # 훈련 데이터셋에 대해 훈련\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[0].to(device)  # batch[0] -> input_ids\n",
    "            attention_mask = batch[1].to(device)  # batch[1] -> attention_mask\n",
    "            labels = batch[2].to(device)  # batch[2] -> labels\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 모델의 출력을 얻습니다.\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # 예측값을 통해 정확도 계산\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            correct = (preds == labels).sum().item()\n",
    "            total = labels.numel()\n",
    "            train_correct += correct\n",
    "            train_total += total\n",
    "\n",
    "        # 훈련 정확도\n",
    "        train_accuracy = 100 * train_correct / train_total\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # 검증 데이터셋에 대해 평가\n",
    "        model.eval()  # 모델을 평가 모드로 설정\n",
    "        test_loss, test_correct, test_total = 0, 0, 0\n",
    "\n",
    "        with torch.no_grad():  # 평가시 기울기 계산을 비활성화\n",
    "            for batch in test_loader:\n",
    "                input_ids = batch[0].to(device)  # batch[0] -> input_ids\n",
    "                attention_mask = batch[1].to(device)  # batch[1] -> attention_mask\n",
    "                labels = batch[2].to(device)  # batch[2] -> labels\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                logits = outputs.logits\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # 예측값을 통해 정확도 계산\n",
    "                preds = torch.argmax(logits, dim=-1)\n",
    "                correct = (preds == labels).sum().item()\n",
    "                total = labels.numel()\n",
    "                test_correct += correct\n",
    "                test_total += total\n",
    "\n",
    "        # 검증 정확도\n",
    "        test_accuracy = 100 * test_correct / test_total\n",
    "        test_losses.append(test_loss / len(test_loader))\n",
    "        test_accuracies.append(test_accuracy)\n",
    "\n",
    "        # 에폭별로 결과 출력\n",
    "        print(f\"{model_type} Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss / len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "        print(f\"Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    return train_losses, train_accuracies, test_losses, test_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a92266c6-5986-42d7-9b74-ae480401b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. 모델 훈련 및 평가 실행 (Pretrained vs Non-pretrained 모델 비교)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "35b47b7b-d03f-402e-8f51-2492ad2bac5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Epoch 1/3\n",
      "Train Loss: 0.0049, Train Accuracy: 99.97%\n",
      "Test Loss: 0.0001, Test Accuracy: 100.00%\n",
      "Pretrained Epoch 2/3\n",
      "Train Loss: 0.0001, Train Accuracy: 100.00%\n",
      "Test Loss: 0.0000, Test Accuracy: 100.00%\n",
      "Pretrained Epoch 3/3\n",
      "Train Loss: 0.0000, Train Accuracy: 100.00%\n",
      "Test Loss: 0.0000, Test Accuracy: 100.00%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 17.55 GB, other allocations: 509.98 MB, max allowed: 18.13 GB). Tried to allocate 150.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m train_losses_pretrained, train_accuracies_pretrained, test_losses_pretrained, test_accuracies_pretrained \u001b[38;5;241m=\u001b[39m train_and_evaluate(\n\u001b[1;32m      2\u001b[0m     pretrained_model, train_loader, test_loader, optimizer_pretrained, device, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPretrained\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 5\u001b[0m train_losses_non_pretrained, train_accuracies_non_pretrained, test_losses_non_pretrained, test_accuracies_non_pretrained \u001b[38;5;241m=\u001b[39m train_and_evaluate(\n\u001b[1;32m      6\u001b[0m     non_pretrained_model, train_loader, test_loader, optimizer_non_pretrained, device, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-pretrained\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n",
      "Cell \u001b[0;32mIn[95], line 18\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(model, train_loader, test_loader, optimizer, device, num_epochs, model_type)\u001b[0m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 모델의 출력을 얻습니다.\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     20\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1890\u001b[0m, in \u001b[0;36mBertForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1885\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1886\u001b[0m \u001b[38;5;124;03m    Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\u001b[39;00m\n\u001b[1;32m   1887\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1888\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1890\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(\n\u001b[1;32m   1891\u001b[0m     input_ids,\n\u001b[1;32m   1892\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1893\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[1;32m   1894\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1895\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1896\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1897\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1898\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1899\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1900\u001b[0m )\n\u001b[1;32m   1902\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1904\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(sequence_output)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m   1143\u001b[0m     embedding_output,\n\u001b[1;32m   1144\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   1145\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1146\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m   1147\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[1;32m   1148\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1149\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1150\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1151\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1152\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1153\u001b[0m )\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[1;32m    696\u001b[0m         hidden_states,\n\u001b[1;32m    697\u001b[0m         attention_mask,\n\u001b[1;32m    698\u001b[0m         layer_head_mask,\n\u001b[1;32m    699\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    700\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    701\u001b[0m         past_key_value,\n\u001b[1;32m    702\u001b[0m         output_attentions,\n\u001b[1;32m    703\u001b[0m     )\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:627\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    624\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    625\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 627\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, attention_output\n\u001b[1;32m    629\u001b[0m )\n\u001b[1;32m    630\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/transformers/pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 639\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m    640\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 539\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    540\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nabakgood/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 17.55 GB, other allocations: 509.98 MB, max allowed: 18.13 GB). Tried to allocate 150.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "train_losses_pretrained, train_accuracies_pretrained, test_losses_pretrained, test_accuracies_pretrained = train_and_evaluate(\n",
    "    pretrained_model, train_loader, test_loader, optimizer_pretrained, device, num_epochs=3, model_type=\"Pretrained\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6fd082-ed71-4b4b-b2ff-bb7f3a913a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_non_pretrained, train_accuracies_non_pretrained, test_losses_non_pretrained, test_accuracies_non_pretrained = train_and_evaluate(\n",
    "    non_pretrained_model, train_loader, test_loader, optimizer_non_pretrained, device, num_epochs=3, model_type=\"Non-pretrained\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29b9d9-4b31-4b8c-b14d-f030b4edb2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. 손실 및 정확도 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c8cd009c-e4f9-4503-8d21-18e083bdb470",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses_non_pretrained' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_losses_pretrained, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPretrained Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_losses_non_pretrained, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-pretrained Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses_non_pretrained' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAH5CAYAAABDMQ1IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9dElEQVR4nO3de3xU5YH/8e8kmUkESUSQAAW5qAXilQRF0EirGC7VFWtLbN0UL1WjIoSboL72t+52dwMEEFQI0gaw1RKEiNJWtqSrBAoBCw14SbQqILSS0rQ6AZRLkuf3x+kMhFzI5PbM5fN+veaVx5NnTr4ZD69vTjLnPC5jjBEAAAhqUbYDAACAc6OwAQAIARQ2AAAhgMIGACAEUNgAAIQAChsAgBBAYQMAEAJibAdoTzU1Nfr888/VqVMnuVwu23EAABHOGKMjR46oZ8+eiopq/Bw6ogr7888/V+/evW3HAACgloMHD6pXr16Nzomowu7UqZMk54WJj4+3nAYAEOkqKyvVu3dvfz81JqIK2/dr8Pj4eAobABA0mvJnWt50BgBACKCwAQAIARQ2AAAhgMIGACAEUNgAAIQAChsAgBBAYQMAEAIobAAAQgCFDQBACGhWYS9ZskT9+vVTXFycUlJStGXLlkbnFxUVKSUlRXFxcerfv7+WLl1aZ05BQYGSkpIUGxurpKQkrVu3rtbnn3nmGblcrlqP7t27Nyc+AAAhJ+DCXr16tbKysvT000+rpKREqampGjNmjA4cOFDv/H379mns2LFKTU1VSUmJnnrqKU2aNEkFBQX+OcXFxUpPT1dGRob27NmjjIwMjR8/Xjt27Ki1r8svv1yHDh3yP957771A4wMAEJJcxhgTyBOGDh2q5ORk5ebm+rcNGjRI48aNU3Z2dp35M2fO1Pr161VWVubflpmZqT179qi4uFiSlJ6ersrKSm3YsME/Z/To0ercubNWrVolyTnDfv3117V79+6AvsEzVVZWKiEhQV6vl3uJAwCsC6SXAjrDPnnypHbt2qW0tLRa29PS0rRt27Z6n1NcXFxn/qhRo7Rz506dOnWq0Tln7/Pjjz9Wz5491a9fP919993au3dvo3lPnDihysrKWg8AAEJRQIVdUVGh6upqJSYm1tqemJio8vLyep9TXl5e7/yqqipVVFQ0OufMfQ4dOlQ///nP9dvf/lY//elPVV5eruHDh+vvf/97g3mzs7OVkJDgf7AWNgAgVDXrTWdnLwNmjGl0abD65p+9/Vz7HDNmjO666y5deeWVGjlypH7zm99Ikl566aUGv+6TTz4pr9frfxw8ePAc3xkAAMEpoPWwu3btqujo6Dpn04cPH65zhuzTvXv3eufHxMSoS5cujc5paJ+S1LFjR1155ZX6+OOPG5wTGxur2NjYRr8nAABCQUBn2B6PRykpKSosLKy1vbCwUMOHD6/3OcOGDaszf+PGjRoyZIjcbnejcxrap+T8fbqsrEw9evQI5FtoVVVV1r40ACDSmADl5+cbt9tt8vLyTGlpqcnKyjIdO3Y0+/fvN8YYM2vWLJORkeGfv3fvXtOhQwczZcoUU1paavLy8ozb7TZr1671z9m6dauJjo42s2fPNmVlZWb27NkmJibGbN++3T9n2rRpZtOmTWbv3r1m+/bt5rbbbjOdOnXyf92m8Hq9RpLxer2Bftu17NplzMiRxjz4YIt2AwCIcIH0UsCFbYwxixcvNn369DEej8ckJyeboqIi/+cmTJhgRowYUWv+pk2bzODBg43H4zF9+/Y1ubm5dfa5Zs0aM2DAAON2u83AgQNNQUFBrc+np6ebHj16GLfbbXr27Gm++93vmg8++CCg3K1V2Fu2GCMZ4/EYc+hQi3YFAIhggfRSwNdhh7LWvA77hhukbdukWbOkei4/BwDgnNrsOmyc9sQTzsfcXInLuwEAbY3Cbqbbb5cGDZK8XmnZMttpAADhjsJupqgoacYMZ/zss9KJE3bzAADCG4XdAj/8odSzp/T559Irr9hOAwAIZxR2C8TGSlOmOOOcHKmmxm4eAED4orBb6KGHpIQE6cMPpV/9ynYaAEC4orBbKD5eeuQRZzxnjhQ5F8kBANoThd0KJk92fj1eXCxt3Wo7DQAgHFHYraB7d2nCBGc8Z47dLACA8ERht5Jp0ySXS/r1r6X337edBgAQbijsVvLNb0rf/a4znjfPbhYAQPihsFvRzJnOx1dekQ4etJsFABBeKOxWdO210re+5ayT/eyzttMAAMIJhd3KfGfZy5ZJX3xhNwsAIHxQ2K1s1CjpqqukY8ekJUtspwEAhAsKu5W5XKeX3ly0SPr6a7t5AADhgcJuA+npUp8+0t/+Jq1caTsNACAcUNhtICbGuS5bci7xqq62mwcAEPoo7DZy//1Sly7S3r1SQYHtNACAUEdht5GOHaWJE50xi4IAAFqKwm5DEydK550n/fGP0ltv2U4DAAhlFHYb6tpVeuABZ8yiIACAlqCw29i0aVJ0tFRY6JxpAwDQHBR2G+vb17nMS5JycqxGAQCEMAq7HcyY4Xx89VXnXeMAAASKwm4H11zj3LK0pkaaP992GgBAKKKw24lvUZDly507oAEAEAgKu51861vSkCHS8ePS88/bTgMACDUUdjtxuU6fZb/wgnT0qN08AIDQQmG3ozvvlC691FknOy/PdhoAQCihsNtRdLQ0fbozXrBAOnXKbh4AQOigsNvZhAlSYqJ04ICUn287DQAgVFDY7SwuTpo82RnPncuiIACApqGwLcjMlM4/X3r/fWnDBttpAAChgMK2oHNn6eGHnTGLggAAmoLCtiQrS3K7pc2bpe3bbacBAAQ7CtuSXr2ke+5xxnPn2s0CAAh+FLZFTzzhfHz9demjj6xGAQAEOQrbokGDpH/5F+ed4vPm2U4DAAhmFLZlvrPsn/9cOnTIbhYAQPCisC274QbncfKktHCh7TQAgGBFYQcB36IgS5dKXq/dLACA4ERhB4HvfEdKSpIqK6UXX7SdBgAQjCjsIBAVJc2Y4YwXLpROnLAaBwAQhCjsIPHDHzrXZh86JL38su00AIBgQ2EHCY9HmjLFGefkSDU1dvMAAIILhR1EHnxQuuAC5yYqb7xhOw0AIJhQ2EGkUyfp0Ued8Zw5LL0JADiNwg4ykyZJsbHSjh3Sli220wAAggWFHWQSE6V773XGLL0JAPChsIPQ9OnOpV5vvim9957tNACAYEBhB6FLL5XuussZ5+TYzQIACA4UdpDyLQqyapV04IDdLAAA+yjsIDVkiHTzzVJVlfTss7bTAABso7CDmG9RkJ/+VPrHP+xmAQDYRWEHsVtvla65Rjp2TFq82HYaAIBNFHYQc7lO/y37ueekr76ymwcAYA+FHeS+/32pb1+pokJaudJ2GgCALRR2kIuJkaZNc8bz5jlvQgMARB4KOwTcf7/Utau0b5+0dq3tNAAAGyjsENChg/T448547lwWBQGASERhh4jHHnOKu6RE+t3vbKcBALQ3CjtEdOki/fjHzphFQQAg8lDYIWTqVCk6Wvq//5N27bKdBgDQnijsENKnj3T33c547ly7WQAA7YvCDjG+G6msXSt9+qndLACA9kNhh5irrpLGjJFqaqT5822nAQC0Fwo7BPnOsleskA4ftpsFANA+KOwQNGKEdN110vHjzj3GAQDhj8IOQS7X6aU3Fy+Wjh61mwcA0PYo7BB1xx3SZZdJX37prJcNAAhvFHaIio6WZsxwxgsWSCdP2s0DAGhbFHYIy8iQuneX/vxnKT/fdhoAQFuisENYXJw0ebIznjvXudQLABCeKOwQl5kpdeokffCB9OabttMAANpKswp7yZIl6tevn+Li4pSSkqItW7Y0Or+oqEgpKSmKi4tT//79tXTp0jpzCgoKlJSUpNjYWCUlJWndunUN7i87O1sul0tZWVnNiR9WLrjAKW2J25UCQDgLuLBXr16trKwsPf300yopKVFqaqrGjBmjAwcO1Dt/3759Gjt2rFJTU1VSUqKnnnpKkyZNUkFBgX9OcXGx0tPTlZGRoT179igjI0Pjx4/Xjh076uzvD3/4g5YtW6arrroq0Ohha/Jkye2WtmyRiottpwEAtAWXMcYE8oShQ4cqOTlZubm5/m2DBg3SuHHjlJ2dXWf+zJkztX79epWVlfm3ZWZmas+ePSr+Z7ukp6ersrJSGzZs8M8ZPXq0OnfurFWrVvm3HT16VMnJyVqyZIn+67/+S9dcc40WLlzYYNYTJ07oxIkT/v+urKxU79695fV6FR8fH8i3HfQeeEBavty53Ov1122nAQA0RWVlpRISEprUSwGdYZ88eVK7du1SWlpare1paWnatm1bvc8pLi6uM3/UqFHauXOnTp061eics/f52GOP6Tvf+Y5GjhzZpLzZ2dlKSEjwP3r37t2k54Ui3yVeb7whffih3SwAgNYXUGFXVFSourpaiYmJtbYnJiaqvLy83ueUl5fXO7+qqkoVFRWNzjlzn/n5+frjH/9Y71l8Q5588kl5vV7/4+DBg01+bqgZONA5u5aknBy7WQAAra9ZbzpzuVy1/tsYU2fbueafvb2xfR48eFCTJ0/Wyy+/rLi4uCbnjI2NVXx8fK1HOPPdrvQXv5D+8he7WQAArSugwu7atauio6PrnE0fPny4zhmyT/fu3eudHxMToy5dujQ6x7fPXbt26fDhw0pJSVFMTIxiYmJUVFSk5557TjExMaqurg7k2whbw4ZJqanSqVPSokW20wAAWlNAhe3xeJSSkqLCwsJa2wsLCzV8+PB6nzNs2LA68zdu3KghQ4bI7XY3Ose3z1tuuUXvvfeedu/e7X8MGTJE99xzj3bv3q3o6OhAvo2w5lt6c+lS5z7jAIAwYQKUn59v3G63ycvLM6WlpSYrK8t07NjR7N+/3xhjzKxZs0xGRoZ//t69e02HDh3MlClTTGlpqcnLyzNut9usXbvWP2fr1q0mOjrazJ4925SVlZnZs2ebmJgYs3379gZzjBgxwkyePDmg7F6v10gyXq83sG86hFRXG3P55cZIxmRn204DAGhMIL0U8N+w09PTtXDhQv3nf/6nrrnmGm3evFlvvvmm+vTpI0k6dOhQrWuy+/XrpzfffFObNm3SNddco5/85Cd67rnndNddd/nnDB8+XPn5+VqxYoWuuuoqrVy5UqtXr9bQoUNb/ANJpImKOn2WvWiRs2Y2ACD0BXwddigL5Hq3UHbypHTJJc6iIMuWSQ8+aDsRAKA+bXYdNkKDxyNNneqMc3Ik3pMHAKGPwg5TDz4ode4sffyxczMVAEBoo7DD1PnnS48+6oznzJEi5w8fABCeKOwwNmmSs2b2O+9IRUW20wAAWoLCDmPdukn33eeMWXoTAEIbhR3mpk1zLvXasEF6913baQAAzUVhh7lLLpG+9z1nzFk2AIQuCjsC+BYFyc+XPvvMbhYAQPNQ2BEgOVkaOdK5HnvBAttpAADNQWFHCN/tSn/2M+nvf7ebBQAQOAo7QowcKQ0eLH31lfTCC7bTAAACRWFHCJfr9N+yn3/eKW4AQOigsCPIXXdJ/fo5vxJfvtx2GgBAICjsCBITI02f7oznz5eqquzmAQA0HYUdYe67T7roImn/fmnNGttpAABNRWFHmPPOkx5/3BmzKAgAhA4KOwI99pjUsaO0Z4+0caPtNACApqCwI9CFFzrrZUvcrhQAQgWFHaGmTHHehPbWW9LOnbbTAADOhcKOUBdfLP3gB854zhy7WQAA50ZhR7AZM5yPBQXSJ5/YzQIAaByFHcGuvFIaO9Z5p/i8ebbTAAAaQ2FHON/tSleulMrLrUYBADSCwo5wqanS9ddLJ0449xgHAAQnCjvCuVynl95cskQ6csRuHgBA/Shs6I47pAEDpC+/lJYts50GAFAfChuKijr9jvFnn5VOnrSbBwBQF4UNSdK//qvUo4f0l79Iv/yl7TQAgLNR2JAkxcZKWVnOeO5cqabGahwAwFkobPg9/LAUHy+VlUm/+Y3tNACAM1HY8EtIkDIznTG3KwWA4EJho5asLMnjkbZudR4AgOBAYaOWHj2kH/3IGbP0JgAEDwobdUyf7txQZf16qbTUdhoAgERhox4DBkjjxjnjnByrUQAA/0Rho16+RUFeeUX685/tZgEAUNhowNCh0k03SadOSQsX2k4DAKCw0SDfWfaLL0pffGE3CwBEOgobDRozRrriCunoUWnpUttpACCyUdho0JlLby5aJB0/bjcPAEQyChuNuvtu6eKLpb/+VXrpJdtpACByUdholNstTZ3qjOfNk6qr7eYBgEhFYeOcHnhA6txZ+uQTad0622kAIDJR2Din88+XJk50xnPmSMbYzQMAkYjCRpM8/rgUFyft3Clt2mQ7DQBEHgobTXLRRdL99ztjlt4EgPZHYaPJpk2ToqKk3/5W2r3bdhoAiCwUNpqsf39p/HhnzNKbANC+KGwExHcjlVdflfbts5sFACIJhY2ADB4s3Xqrcz32ggW20wBA5KCwETDfoiB5edLf/mY3CwBECgobAbv5ZiklRfr6a2nxYttpACAyUNgI2JmLgjz/vHTsmN08ABAJKGw0y113SZdcIv3jH86vxgEAbYvCRrNER0vTpzvj+fOlU6fs5gGAcEdho9kmTJC6dZMOHHAu8wIAtB0KG8123nnSpEnOeO5cFgUBgLZEYaNFHn1U6thRevdd55alAIC2QWGjRTp3lh56yBmzKAgAtB0KGy02ZYoUE+Msu/nOO7bTAEB4orDRYr17S/fc44xZFAQA2gaFjVYxY4bz8bXXpD/9yW4WAAhHFDZaxeWXS7fd5rxTfN4822kAIPxQ2Gg1vkVBXnpJKi+3mwUAwg2FjVZzww3SsGHSyZPSokW20wBAeKGw0WpcrtNn2bm5UmWl3TwAEE4obLSq22+XBg6UvF5p2TLbaQAgfFDYaFVRUaffMf7ss9KJE3bzAEC4oLDR6u65R+rZU/r8c+mVV2ynAYDwQGGj1cXGOnc/k6ScHKmmxm4eAAgHFDbaxEMPSQkJ0ocfSr/6le00ABD6KGy0ifh46ZFHnPGcOSy9CQAtRWGjzUyeLHk8UnGxtHWr7TQAENoobLSZ7t2lCROcMUtvAkDLNKuwlyxZon79+ikuLk4pKSnasmVLo/OLioqUkpKiuLg49e/fX0uXLq0zp6CgQElJSYqNjVVSUpLWrVtX6/O5ubm66qqrFB8fr/j4eA0bNkwbNmxoTny0o+nTnRuq/PrX0vvv204DAKEr4MJevXq1srKy9PTTT6ukpESpqakaM2aMDhw4UO/8ffv2aezYsUpNTVVJSYmeeuopTZo0SQUFBf45xcXFSk9PV0ZGhvbs2aOMjAyNHz9eO3bs8M/p1auXZs+erZ07d2rnzp26+eabdccdd+iDDz5oxreN9vLNb0rf/a4zZlEQAGg+lzGBvR1o6NChSk5OVm5urn/boEGDNG7cOGVnZ9eZP3PmTK1fv15lZWX+bZmZmdqzZ4+Ki4slSenp6aqsrKx1xjx69Gh17txZq1atajDLhRdeqJycHD3wwANNyl5ZWamEhAR5vV7Fx8c36TlouXfekYYOlWJipL17nfWzAQCB9VJAZ9gnT57Url27lJaWVmt7Wlqatm3bVu9ziouL68wfNWqUdu7cqVOnTjU6p6F9VldXKz8/X8eOHdOwYcMazHvixAlVVlbWeqD9XXed9K1vSVVVzt3PAACBC6iwKyoqVF1drcTExFrbExMTVd7Aeorl5eX1zq+qqlJFRUWjc87e53vvvafzzz9fsbGxyszM1Lp165SUlNRg3uzsbCUkJPgfvTm1s8a3KMiyZdIXX9jNAgChqFlvOnO5XLX+2xhTZ9u55p+9vSn7HDBggHbv3q3t27frkUce0YQJE1RaWtrg133yySfl9Xr9j4MHDzb+jaHNjBolXXWVdOyYtGSJ7TQAEHoCKuyuXbsqOjq6zpnv4cOH65wh+3Tv3r3e+TExMerSpUujc87ep8fj0aWXXqohQ4YoOztbV199tRY1svBybGys/13lvgfscLmkJ55wxosWSV9/bTcPAISagArb4/EoJSVFhYWFtbYXFhZq+PDh9T5n2LBhdeZv3LhRQ4YMkdvtbnROQ/v0McboBMtBhYzx46U+faS//U166SXbaQAgxJgA5efnG7fbbfLy8kxpaanJysoyHTt2NPv37zfGGDNr1iyTkZHhn793717ToUMHM2XKFFNaWmry8vKM2+02a9eu9c/ZunWriY6ONrNnzzZlZWVm9uzZJiYmxmzfvt0/58knnzSbN282+/btM++++6556qmnTFRUlNm4cWOTs3u9XiPJeL3eQL9ttJJFi4yRjLnkEmOqqmynAQC7AumlgAvbGGMWL15s+vTpYzwej0lOTjZFRUX+z02YMMGMGDGi1vxNmzaZwYMHG4/HY/r27Wtyc3Pr7HPNmjVmwIABxu12m4EDB5qCgoJan7///vv9X/Oiiy4yt9xyS0BlbQyFHQyOHjWmSxentFevtp0GAOwKpJcCvg47lHEddnB45hnpP/5DSkmR/vAH5+/bABCJ2uw6bKA1TJwonXeetGuX9NZbttMAQGigsNHuunaVfDenY1EQAGgaChtWTJsmRUdLhYXSH/9oOw0ABD8KG1b07etc5iVJOTlWowBASKCwYY3vRiqvvuosCgIAaBiFDWuuuca5ZWlNjTR/vu00ABDcKGxY5TvLXr7cuQMaAKB+FDas+va3pSFDpOPHpeeft50GAIIXhQ2rXK7TS2++8IJ09KjdPAAQrChsWHfnndKllzrrZOfl2U4DAMGJwoZ10dHS9OnOeMEC6dQpu3kAIBhR2AgKEyZI3bpJBw5I+fm20wBA8KGwERTi4qTJk53x3LlS5CxJAwBNQ2EjaDzyiHT++dL770sbNthOAwDBhcJG0OjcWXr4YWfMoiAAUBuFjaCSlSW53dLmzdL27bbTAEDwoLARVHr1ku65xxnPnWs3CwAEEwobQcd3u9LXX5c++shqFAAIGhQ2gs6gQdK//IvzTvF582ynAYDgQGEjKPnOsn/+c+nQIbtZACAYUNgISjfc4DxOnpQWLrSdBgDso7ARtHyLgixdKnm9drMAgG0UNoLWd74jJSVJlZXSiy/aTgMAdlHYCFpRUdKMGc544ULpxAmrcQDAKgobQe2HP5S+8Q3njWcvv2w7DQDYQ2EjqHk80pQpzjgnR6qpsZsHAGyhsBH0HnpIuuAC5yYqb7xhOw0A2EFhI+h16iQ9+qgznjOHpTcBRCYKGyFh0iQpNlbasUPassV2GgBofxQ2QkJionTvvc6YpTcBRCIKGyFj+nTJ5ZLefFN67z3baQCgfVHYCBmXXirddZczzsmxmwUA2huFjZDiu13pqlXSgQN2swBAe6KwEVKGDJFuvlmqqpKefdZ2GgBoPxQ2Qo5v6c2f/lT6xz/sZgGA9kJhI+SkpUnXXCMdOyYtXmw7DQC0DwobIcflOn2W/dxz0tdf280DAO2BwkZI+v73pb59pYoKacUK22kAoO1R2AhJMTHStGnOeN48501oABDOKGyErPvvl7p0kfbtkwoKbKcBgLZFYSNkdeggPf64M2ZREADhjsJGSJs40SnukhLpd7+znQYA2g6FjZDWpYv04x87YxYFARDOKGyEvClTpOho6f/+T9q1y3YaAGgbFDZCXt++0t13O+O5c61GAYA2Q2EjLPhupLJ2rfTpp3azAEBboLARFq66Sho9WqqpkebPt50GAFofhY2w4Vt6c8UK6fBhu1kAoLVR2AgbI0ZI110nHT/u3GMcAMIJhY2wceaiIIsXS0eP2s0DAK2JwkZYGTdOuuwy6csvnfWyASBcUNgIK9HR0owZznjBAunkSbt5AKC1UNgIOxkZUmKi9Oc/S/n5ttMAQOugsBF24uKkrCxnPHeuc6kXAIQ6ChthKTNT6tRJ+uAD6c03bacBgJajsBGWLrhAevhhZ8ztSgGEAwobYSsrS3K7pS1bpOJi22kAoGUobIStb3zDeQOaxNKbAEIfhY2wNn268/GNN6QPP7SbBQBagsJGWBs0SLrjDmeck2M3CwC0BIWNsOdbFOQXv5D+8he7WQCguShshL1hw6TUVOnUKWnRIttpAKB5KGxEBN+iIEuXOvcZB4BQQ2EjIowdK11+uXTkiFPaABBqKGxEhKio02fZixY5a2YDQCihsBEx7r5b6tVLKi933oAGAKGEwkbE8HikqVOdcU6OVF1tNw8ABILCRkR58EGpc2fp44+dm6kAQKigsBFRzj9fevRRZzxnjmSM3TwA0FQUNiLOpEnOmtnvvCMVFdlOAwBNQ2Ej4nTrJt13nzNm6U0AoYLCRkSaNs251GvDBundd22nAYBzo7ARkS65RPre95wxZ9kAQgGFjYjlu5FKfr702Wd2swDAuVDYiFgpKdIttzjXYy9YYDsNADSuWYW9ZMkS9evXT3FxcUpJSdGWLVsanV9UVKSUlBTFxcWpf//+WlrPzZwLCgqUlJSk2NhYJSUlad26dbU+n52drWuvvVadOnVSt27dNG7cOH300UfNiQ/4+Zbe/NnPpL//3W4WAGhMwIW9evVqZWVl6emnn1ZJSYlSU1M1ZswYHThwoN75+/bt09ixY5WamqqSkhI99dRTmjRpkgoKCvxziouLlZ6eroyMDO3Zs0cZGRkaP368duzY4Z9TVFSkxx57TNu3b1dhYaGqqqqUlpamY8eONePbBhwjR0qDB0tffSUtXmw7DQA0zGVMYLeOGDp0qJKTk5Wbm+vfNmjQII0bN07Z2dl15s+cOVPr169XWVmZf1tmZqb27Nmj4uJiSVJ6eroqKyu1YcMG/5zRo0erc+fOWrVqVb05/va3v6lbt24qKirSTTfd1KTslZWVSkhIkNfrVXx8fJOeg/CXny/94AdS167O37I7dLCdCECkCKSXAjrDPnnypHbt2qW0tLRa29PS0rRt27Z6n1NcXFxn/qhRo7Rz506dOnWq0TkN7VOSvF6vJOnCCy9scM6JEydUWVlZ6wGc7Xvfk/r1kyoqpOXLbacBgPoFVNgVFRWqrq5WYmJire2JiYkqLy+v9znl5eX1zq+qqlJFRUWjcxrapzFGU6dO1Y033qgrrriiwbzZ2dlKSEjwP3r37n3O7xGRJyZGmj7dGc+fL1VV2c0DAPVp1pvOXC5Xrf82xtTZdq75Z28PZJ8TJ07Uu+++2+Cvy32efPJJeb1e/+PgwYONzkfkuvde51fi+/dLa9bYTgMAdQVU2F27dlV0dHSdM9/Dhw/XOUP26d69e73zY2Ji1KVLl0bn1LfPxx9/XOvXr9fbb7+tXr16NZo3NjZW8fHxtR5AfTp0cO4xLrEoCIDgFFBhezwepaSkqLCwsNb2wsJCDR8+vN7nDBs2rM78jRs3asiQIXK73Y3OOXOfxhhNnDhRr732mt566y3169cvkOjAOT32mFPce/ZIGzfaTgMAZzEBys/PN2632+Tl5ZnS0lKTlZVlOnbsaPbv32+MMWbWrFkmIyPDP3/v3r2mQ4cOZsqUKaa0tNTk5eUZt9tt1q5d65+zdetWEx0dbWbPnm3KysrM7NmzTUxMjNm+fbt/ziOPPGISEhLMpk2bzKFDh/yPr776qsnZvV6vkWS8Xm+g3zYixOTJxkjG3Hyz7SQAIkEgvRRwYRtjzOLFi02fPn2Mx+MxycnJpqioyP+5CRMmmBEjRtSav2nTJjN48GDj8XhM3759TW5ubp19rlmzxgwYMMC43W4zcOBAU1BQUDuoVO9jxYoVTc5NYeNcPvvMmJgYp7T/8AfbaQCEu0B6KeDrsEMZ12GjKX70I+kXv3Au9+INaADaUptdhw1EghkznI8FBdInn9jNAgA+FDZwliuvlMaOdd4pPm+e7TQA4KCwgXr4FgVZuVJq4P49ANCuKGygHqmp0tCh0okT0vPP204DABQ2UC+X6/RZ9pIl0pEjdvMAAIUNNOCOO6RvflP68ktp2TLbaQBEOgobaEBU1Ol3jD/7rHTypN08ACIbhQ00IiND6tFD+stfpF/+0nYaAJGMwgYaERsrZWU547lzpZoaq3EARDAKGziHhx+W4uOlsjLpN7+xnQZApKKwgXNISJAyM53xnDl2swCIXBQ20ASTJ0sej7R1q/MAgPZGYQNN0LOn8wY0yflbNgC0NwobaKIZM5wbqqxfL5WW2k4DINJQ2EATDRggjRvnjHNyrEYBEIEobCAATzzhfHzlFenPf7abBUBkobCBAFx/vXTTTdKpU9LChbbTAIgkFDYQIN+iIC++KH3xhd0sACIHhQ0EaMwY6YorpKNHpaVLbacBECkobCBALtfpv2UvWiQdP243D4DIQGEDzXD33dLFF0t//av00ku20wCIBBQ20AxutzR1qjOeN0+qrrabB0D4o7CBZnrgAalzZ+mTT6R162ynARDuKGygmc4/X5o40RnPmSMZYzcPgPBGYQMt8PjjUlyctHOntGmT7TQAwhmFDbTARRdJ99/vjFl6E0BborCBFpo2TYqKkn77W2n3bttpAIQrChtoof79pfHjnTGLggBoKxQ20Ap8N1JZvVrav99qFABhisIGWsHgwdKttzrXY8+fbzsNgHBEYQOtxLcoSF6eVFFhNwuA8ENhA63k5pul5GTp66+lF16wnQZAuKGwgVbicp0+y37+eenYMbt5AIQXChtoRXfd5bxr/B//kJYvt50GQDihsIFWFB0tTZ/ujOfPl06dspsHQPigsIFWdu+9Urdu0mefSa++ajsNgHBBYQOt7LzzpEmTnPHcuSwKAqB1UNhAG3jkEaljR+ndd51blgJAS1HYQBu48ELpoYecMYuCAGgNFDbQRqZMkWJinGU333nHdhoAoY7CBtpI797SD3/ojOfOtZsFQOijsIE25FsU5LXXpD/9yW4WAKGNwgba0OWXS7fd5rxTfN4822kAhDIKG2hjvrPsl16SysvtZgEQuihsoI3deKM0bJh08qS0aJHtNABCFYUNtLEzFwXJzZUqK+3mARCaKGygHdx+uzRwoOT1SsuW2U4DIBRR2EA7iIqSZsxwxs8+K504YTcPgNBDYQPt5J57pJ49pc8/l155xXYaAKGGwgbaSWyslJXljHNypJoaq3EAhBgKG2hHDz8sJSRIH34o/epXttMACCUUNtCO4uOdlbwkZ1EQlt4E0FQUNtDOJk2SPB6puFjautV2GgChgsIG2lmPHtKECc6YpTcBNBWFDVgwfbpzQ5Vf/1p6/33baQCEAgobsOCb35TuvNMZsygIgKagsAFLfLcrfeUV6eBBu1kABD8KG7Dkuuukb31Lqqpy7n4GAI2hsAGLfEtvLlsmffGF3SwAghuFDVg0erR01VXSsWPSkiW20wAIZhQ2YJHLdfose9Ei6euv7eYBELwobMCy8eOliy+W/vY36aWXbKcBEKwobMAyt1uaNs0Zz5snVVfbzQMgOFHYQBB44AHpwgulTz+VCgpspwEQjChsIAh07ChNnOiM585lURAAdVHYQJB4/HHpvPOkXbukt96ynQZAsKGwgSDRtavzq3GJRUEA1EVhA0Fk2jQpOloqLJRKSmynARBMKGwgiPTt61zmJTl/ywYAHwobCDK+G6m8+qq0d6/dLACCB4UNBJlrrpFGjZJqaqQFC2ynARAsKGwgCPnOspcvd+6ABgAUNhCEvv1tacgQ597izz9vOw2AYEBhA0HI5ZJmznTGL7wgHT1qNw8A+yhsIEjdead06aXOOtl5ebbTALCtWYW9ZMkS9evXT3FxcUpJSdGWLVsanV9UVKSUlBTFxcWpf//+Wrp0aZ05BQUFSkpKUmxsrJKSkrRu3bpan9+8ebNuv/129ezZUy6XS6+//npzogMhIzpamj7dGS9YIJ06ZTcPALsCLuzVq1crKytLTz/9tEpKSpSamqoxY8bowIED9c7ft2+fxo4dq9TUVJWUlOipp57SpEmTVHDGCgfFxcVKT09XRkaG9uzZo4yMDI0fP147duzwzzl27JiuvvpqvfDCC834NoHQNGGC1K2bdOCAlJ9vOw0Am1zGBLbMwNChQ5WcnKzc3Fz/tkGDBmncuHHKzs6uM3/mzJlav369ysrK/NsyMzO1Z88eFRcXS5LS09NVWVmpDRs2+OeMHj1anTt31qpVq+qGdrm0bt06jRs3LpDoqqysVEJCgrxer+Lj4wN6LmDL//yP9PTT0hVXSO++6/x9G0B4CKSXAjrDPnnypHbt2qW0tLRa29PS0rRt27Z6n1NcXFxn/qhRo7Rz506d+ufv+Bqa09A+m+rEiROqrKys9QBCzSOPSOefL73/vnTGz7QAIkxAhV1RUaHq6molJibW2p6YmKjy8vJ6n1NeXl7v/KqqKlVUVDQ6p6F9NlV2drYSEhL8j969e7dof4ANnTtLDz/sjFkUBIhczXrTmeus38kZY+psO9f8s7cHus+mePLJJ+X1ev2PgwcPtmh/gC1ZWZLbLW3eLG3fbjsNABsCKuyuXbsqOjq6zpnv4cOH65wh+3Tv3r3e+TExMerSpUujcxraZ1PFxsYqPj6+1gMIRb16Sffc44xZFASITAEVtsfjUUpKigoLC2ttLyws1PDhw+t9zrBhw+rM37hxo4YMGSK3293onIb2CUSiGTOcj6+/Ln30kdUoACwI+FfiU6dO1c9+9jMtX75cZWVlmjJlig4cOKDMzExJzq+hf/SjH/nnZ2Zm6rPPPtPUqVNVVlam5cuXKy8vT9N9F5hKmjx5sjZu3Kg5c+boww8/1Jw5c/S73/1OWVlZ/jlHjx7V7t27tXv3bknO5WK7d+9u8HIyINwkJUm33y4ZI82bZzsNgHZnmmHx4sWmT58+xuPxmOTkZFNUVOT/3IQJE8yIESNqzd+0aZMZPHiw8Xg8pm/fviY3N7fOPtesWWMGDBhg3G63GThwoCkoKKj1+bfffttIqvOYMGFCk3N7vV4jyXi93oC+XyBY/P73xkjGeDzGfP657TQAWiqQXgr4OuxQxnXYCAc33iht3eqs6MW7xoHQ1mbXYQOwz7f05tKlktdrNwuA9kNhAyHmttucv2dXVkovvmg7DYD2QmEDISYq6vQ7xhculE6csBoHQDuhsIEQ9MMfSt/4hnTokPTyy7bTAGgPFDYQgjweacoUZ5yTI9XU2M0DoO1R2ECIeughKSHBuYnKG2/YTgOgrVHYQIjq1El69FFnPGeOc0MVAOGLwgZC2OTJUmystGOHtGWL7TQA2hKFDYSwxETp3nudMTdRAcIbhQ2EuGnTJJdLevNN6b33bKcB0FYobCDEXXaZdNddzjgnx24WAG2HwgbCgO92patWSSxgB4QnChsIA9deK33721JVlfTss7bTAGgLFDYQJmbOdD7+9KfSP/5hNwuA1kdhA2EiLU26+mrp2DFp8WLbaQC0NgobCBMu1+m/ZT/3nPT113bzAGhdFDYQRsaPl/r2lSoqpBUrbKcB0JoobCCMxMQ412VL0rx5zpvQAIQHChsIM/fdJ3XpIu3bJxUU2E4DoLVQ2ECY6dhRevxxZ8yiIED4oLCBMDRxotShg1RSIv3ud7bTAGgNFDYQhrp0kR54wBnPnWs3C4DWQWEDYWrqVCk62jnD3rXLdhoALUVhA2Gqb1/p7rudMWfZQOijsIEwNmOG83HtWunTT+1mAdAyFDYQxq6+Who9WqqpkebPt50GQEtQ2ECY8y0KsmKFdPiw3SwAmo/CBsLciBHO8pvHj0vPP287DYDmorCBMOdynT7LXrxYOnrUbh4AzUNhAxFg3DjpssukL75w1ssGEHoobCACREeffsf4ggXSyZN28wAIHIUNRIiMDCkxUfrzn6X8fNtpAASKwgYiRFyclJXljOfOdS71AhA6KGwggmRmSp06SR98IL35pu00AAJBYQMR5IILpIcfdsbcrhQILRQ2EGGysiS3W9qyRSoutp0GQFNR2ECE+cY3nDegSdKcOXazAGg6ChuIQNOnOx/feEP68EO7WQA0DYUNRKBBg6Q77nDGOTl2swBoGgobiFC+25X+4hfSX/5iNwuAc6OwgQg1bJh0443SqVPSokW20wA4FwobiGC+s+ylS6Uvv7QaBcA5UNhABBs7Vrr8cunIEae0AQQvChuIYFFRpxcFWbTIWTMbQHCisIEI94MfSL16SeXlzhvQAAQnChuIcB6PNHWqM87Jkaqr7eYBUD8KG4B+/GPnPuMff+zcTAVA8KGwAahTJ+mxx5zxnDmSMXbzAKiLwgYgSZo0SYqNld55Ryoqsp0GwNkobACSpG7dpPvuc8YsvQkEHwobgN/06c6lXhs2SO++azsNgDNR2AD8LrlE+t73nDFn2UBwobAB1PLEE87H/Hzps8/sZgFwGoUNoJaUFOmWW5zrsRcssJ0GgA+FDaAO36IgP/uZ9Pe/280CwEFhA6hj5Ehp8GDpq6+kxYttpwEgUdgA6uFynf5b9vPPO8UNwC4KG0C9vvc9qV8/qaJCWr7cdhoAFDaAesXESNOmOeP586WqKrt5gEhHYQNo0H33SV27Svv3S2vW2E4DRDYKG0CDOnRw7jEusSgIYBuFDaBRjz7qFPeePVJhoe00QOSisAE0qksX6cEHnfGcOXazAJGMwgZwTlOnStHR0ltvSTt32k4DRCYKG8A5XXyx9IMfOGMWBQHsoLABNInvRioFBdInn9jNAkQiChtAk1x5pTR2rFRTI82bZzsNEHkobABN5jvLXrlS+utfrUYBIk6M7QAAQsdNN0lDh0o7dkj/7/9JP/qRFBcnxcae/njm2ONx7ksOoOVcxkTOrRAqKyuVkJAgr9er+Ph423GAkLRunfTd7zZ9vq/EGyr19hq73fzwgOATSC9xhg0gIHfc4dyy9J13pBMnpOPHnY++8cmTtef7PhcMbP/Q4BvzwwOag8IGEJCoqMZX7zLGKe2zi9zGOFh/eHC57P/Q4BvHxPDDQ6igsAG0qjPLyLaaGqe0bf7Q4BufOnU6lzHO9uPHJa/X3usjOf+/bP/Q4BvH0EiN4uUBELaiopwiiIuTEhLsZqmpOV3ibf3Dwbk+f+ZSqcZIX3/tPGyLirL/Q4NvHIw/PARhJAAIP1FR0nnnOQ/bqqvb74eHc42rq0/nqqkJnh8eoqPPXeo//7nUt2/7ZWpWYS9ZskQ5OTk6dOiQLr/8ci1cuFCpqakNzi8qKtLUqVP1wQcfqGfPnnriiSeUmZlZa05BQYH+7d/+TZ9++qkuueQS/fd//7fuvPPOFn1dAEBd0dHOCmwdOthOcvqHB9t/sjh+3PmB4cxcX33lPBpy5p852kPAhb169WplZWVpyZIluuGGG/Tiiy9qzJgxKi0t1cUXX1xn/r59+zR27Fg9+OCDevnll7V161Y9+uijuuiii3TXXXdJkoqLi5Wenq6f/OQnuvPOO7Vu3TqNHz9ev//97zV06NBmfV0AQPALph8eqqoCK/sePdo3X8DXYQ8dOlTJycnKzc31bxs0aJDGjRun7OzsOvNnzpyp9evXq6yszL8tMzNTe/bsUXFxsSQpPT1dlZWV2rBhg3/O6NGj1blzZ61atapZX1eSTpw4oRNnvCW0srJSvXv35jpsAEBQCOQ67IBuTXry5Ent2rVLaWlptbanpaVp27Zt9T6nuLi4zvxRo0Zp586dOvXP3yc0NMe3z+Z8XUnKzs5WQkKC/9G7d++mfaMAAASZgAq7oqJC1dXVSkxMrLU9MTFR5eXl9T6nvLy83vlVVVWqqKhodI5vn835upL05JNPyuv1+h8HDx5s2jcKAECQadabzlxnXWVvjKmz7Vzzz97elH0G+nVjY2MVGwwXgwIA0EIBnWF37dpV0dHRdc5qDx8+XOfs16d79+71zo+JiVGXLl0anePbZ3O+LgAA4SSgwvZ4PEpJSVFhYWGt7YWFhRo+fHi9zxk2bFid+Rs3btSQIUPkdrsbnePbZ3O+LgAAYcUEKD8/37jdbpOXl2dKS0tNVlaW6dixo9m/f78xxphZs2aZjIwM//y9e/eaDh06mClTppjS0lKTl5dn3G63Wbt2rX/O1q1bTXR0tJk9e7YpKyszs2fPNjExMWb79u1N/rpN4fV6jSTj9XoD/bYBAGh1gfRSwIVtjDGLFy82ffr0MR6PxyQnJ5uioiL/5yZMmGBGjBhRa/6mTZvM4MGDjcfjMX379jW5ubl19rlmzRozYMAA43a7zcCBA01BQUFAX7cpKGwAQDAJpJdYDxsAAEva7DpsAABgB4UNAEAIoLABAAgBFDYAACGAwgYAIARQ2AAAhAAKGwCAEEBhAwAQAihsAABCQLOW1wxVvpu6VVZWWk4CAMDpPmrKTUcjqrCPHDkiSerdu7flJAAAnHbkyBElJCQ0Oiei7iVeU1Ojzz//XJ06dZLL5WrRviorK9W7d28dPHgwJO9LTn67yG8X+e0i/2nGGB05ckQ9e/ZUVFTjf6WOqDPsqKgo9erVq1X3GR8fH5IHnA/57SK/XeS3i/yOc51Z+/CmMwAAQgCFDQBACKCwmyk2Nlb//u//rtjYWNtRmoX8dpHfLvLbRf7miag3nQEAEKo4wwYAIARQ2AAAhAAKGwCAEEBhAwAQAihsAABCAIX9T0uWLFG/fv0UFxenlJQUbdmypdH5RUVFSklJUVxcnPr376+lS5fWmVNQUKCkpCTFxsYqKSlJ69ata6v4AeV/7bXXdOutt+qiiy5SfHy8hg0bpt/+9re15qxcuVIul6vO4/jx49bzb9q0qd5sH374Ya15wfr633vvvfXmv/zyy/1z2vP137x5s26//Xb17NlTLpdLr7/++jmfE0zHf6D5g+34DzR/sB3/geYPtuM/Oztb1157rTp16qRu3bpp3Lhx+uijj875PBv/BihsSatXr1ZWVpaefvpplZSUKDU1VWPGjNGBAwfqnb9v3z6NHTtWqampKikp0VNPPaVJkyapoKDAP6e4uFjp6enKyMjQnj17lJGRofHjx2vHjh3W82/evFm33nqr3nzzTe3atUvf/va3dfvtt6ukpKTWvPj4eB06dKjWIy4uznp+n48++qhWtssuu8z/uWB+/RctWlQr98GDB3XhhRfq+9//fq157fX6Hzt2TFdffbVeeOGFJs0PtuM/0PzBdvwHmt8nWI7/QPMH2/FfVFSkxx57TNu3b1dhYaGqqqqUlpamY8eONfgca/8GDMx1111nMjMza20bOHCgmTVrVr3zn3jiCTNw4MBa2x5++GFz/fXX+/97/PjxZvTo0bXmjBo1ytx9992tlPq0QPPXJykpyfzHf/yH/79XrFhhEhISWitiowLN//bbbxtJ5osvvmhwn6H0+q9bt864XC6zf/9+/7b2fP3PJMmsW7eu0TnBdvyfqSn562Pz+D9TU/IH2/F/pua8/sF0/BtjzOHDh40kU1RU1OAcW/8GIv4M++TJk9q1a5fS0tJqbU9LS9O2bdvqfU5xcXGd+aNGjdLOnTt16tSpRuc0tM/mak7+s9XU1OjIkSO68MILa20/evSo+vTpo169eum2226rcwbSGlqSf/DgwerRo4duueUWvf3227U+F0qvf15enkaOHKk+ffrU2t4er39zBNPx3xpsHv8tEQzHf2sItuPf6/VKUp3j4Uy2/g1EfGFXVFSourpaiYmJtbYnJiaqvLy83ueUl5fXO7+qqkoVFRWNzmlon83VnPxnmz9/vo4dO6bx48f7tw0cOFArV67U+vXrtWrVKsXFxemGG27Qxx9/bD1/jx49tGzZMhUUFOi1117TgAEDdMstt2jz5s3+OaHy+h86dEgbNmzQj3/841rb2+v1b45gOv5bg83jvzmC6fhvqWA7/o0xmjp1qm688UZdccUVDc6z9W8gopbXbMzZ62MbYxpdM7u++WdvD3SfLdHcr7Vq1So988wzeuONN9StWzf/9uuvv17XX3+9/79vuOEGJScn6/nnn9dzzz3XesH/KZD8AwYM0IABA/z/PWzYMB08eFDz5s3TTTfd1Kx9tlRzv9bKlSt1wQUXaNy4cbW2t/frH6hgO/6bK1iO/0AE4/HfXMF2/E+cOFHvvvuufv/7359zro1/AxF/ht21a1dFR0fX+ann8OHDdX468unevXu982NiYtSlS5dG5zS0z+ZqTn6f1atX64EHHtCrr76qkSNHNjo3KipK1157bav/hNuS/Ge6/vrra2ULhdffGKPly5crIyNDHo+n0blt9fo3RzAd/y0RDMd/a7F1/LdEsB3/jz/+uNavX6+3335bvXr1anSurX8DEV/YHo9HKSkpKiwsrLW9sLBQw4cPr/c5w4YNqzN/48aNGjJkiNxud6NzGtpnczUnv+ScWdx777365S9/qe985zvn/DrGGO3evVs9evRoceYzNTf/2UpKSmplC/bXX3LenfrJJ5/ogQceOOfXaavXvzmC6fhvrmA5/luLreO/JYLl+DfGaOLEiXrttdf01ltvqV+/fud8jrV/A81+u1oYyc/PN2632+Tl5ZnS0lKTlZVlOnbs6H/X4qxZs0xGRoZ//t69e02HDh3MlClTTGlpqcnLyzNut9usXbvWP2fr1q0mOjrazJ4925SVlZnZs2ebmJgYs337duv5f/nLX5qYmBizePFic+jQIf/jyy+/9M955plnzP/+7/+aTz/91JSUlJj77rvPxMTEmB07dljP/+yzz5p169aZP/3pT+b99983s2bNMpJMQUGBf04wv/4+//qv/2qGDh1a7z7b8/U/cuSIKSkpMSUlJUaSWbBggSkpKTGfffZZvfmD7fgPNH+wHf+B5g+24z/Q/D7Bcvw/8sgjJiEhwWzatKnW8fDVV1/55wTLvwEK+58WL15s+vTpYzwej0lOTq71lv4JEyaYESNG1Jq/adMmM3jwYOPxeEzfvn1Nbm5unX2uWbPGDBgwwLjdbjNw4MBa/6Bs5h8xYoSRVOcxYcIE/5ysrCxz8cUXG4/HYy666CKTlpZmtm3bFhT558yZYy655BITFxdnOnfubG688Ubzm9/8ps4+g/X1N8aYL7/80px33nlm2bJl9e6vPV9/32VCDR0PwX78B5o/2I7/QPMH2/HfnOMnmI7/+rJLMitWrPDPCZZ/A6yHDQBACIj4v2EDABAKKGwAAEIAhQ0AQAigsAEACAEUNgAAIYDCBgAgBFDYAACEAAobAIAQQGEDABACKGwAAEIAhQ0AQAj4/xiWy0PGi49uAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Loss curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses_pretrained, label=\"Pretrained Loss\", color=\"blue\")\n",
    "plt.plot(train_losses_non_pretrained, label=\"Non-pretrained Loss\", color=\"red\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies_pretrained, label=\"Pretrained Accuracy\", color=\"blue\")\n",
    "plt.plot(train_accuracies_non_pretrained, label=\"Non-pretrained Accuracy\", color=\"red\")\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce0ea0-bf8a-4997-94b9-6b23b7895bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nabakgood)",
   "language": "python",
   "name": "nabakgood"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
